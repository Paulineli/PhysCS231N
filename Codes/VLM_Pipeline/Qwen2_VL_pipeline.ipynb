{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d2a2ad0",
   "metadata": {},
   "source": [
    "# Qwen2-VL Video Understanding Pipeline (Cleaned)\n",
    "This notebook demonstrates how to set up and use Qwen2-VL for video understanding on Colab. It includes mounting Google Drive, installing dependencies, extracting video frames, and querying the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive to access video files\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e2584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install git+https://github.com/huggingface/transformers@21fac7abba2a37fae86106f87fcf9974fd1e3830 accelerate\n",
    "!apt-get update && apt-get install -y ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e1682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and initialize the Qwen2-VL model\n",
    "import os\n",
    "from transformers import AutoTokenizer, AutoProcessor, Qwen2VLForConditionalGeneration\n",
    "\n",
    "# Initialize tokenizer, processor, and model\n",
    "model_name = 'Qwen/Qwen2-VL-Chat-Base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "processor = AutoProcessor.from_pretrained(model_name)\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(model_name).half().cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58982dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define video and frame output paths\n",
    "video_path = '/content/drive/MyDrive/CS231_project/pumunk_videos/594_1748124142.mp4'\n",
    "frames_dir = '/content/drive/MyDrive/CS231_project/pumunk_videos/frames'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(frames_dir, exist_ok=True)\n",
    "\n",
    "# Extract frames using ffmpeg\n",
    "os.system(f\"ffmpeg -i {video_path} -q:v 2 {frames_dir}/%05d.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13cd522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to sample frames for model input\n",
    "from math import ceil\n",
    "\n",
    "def get_frame_list(output_path, fraction=0.0125):\n",
    "    \"\"\"\n",
    "    Returns a list of frame file paths, sampled uniformly.\n",
    "    fraction: proportion of total frames to return.\n",
    "    \"\"\"\n",
    "    all_frames = sorted(f for f in os.listdir(output_path) if f.endswith('.jpg'))\n",
    "    total = len(all_frames)\n",
    "    step = max(1, ceil(total * fraction))\n",
    "    return [os.path.join(output_path, f) for f in all_frames[::step]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc1791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to query the video model\n",
    "def query_video(prompt, use_frames=True, frames_path=None, video_path=None):\n",
    "    \"\"\"\n",
    "    Send a prompt to the Qwen2-VL model, using either sampled frames or full video.\n",
    "    \"\"\"\n",
    "    if use_frames:\n",
    "        # Process sampled frames\n",
    "        frame_files = get_frame_list(frames_path)\n",
    "        inputs = processor(image=frame_files, text=prompt, return_tensors='pt').to('cuda')\n",
    "    else:\n",
    "        # Process full video\n",
    "        inputs = processor(video=video_path, text=prompt, return_tensors='pt').to('cuda')\n",
    "\n",
    "    outputs = model.generate(**inputs)\n",
    "    return tokenizer.batch_decode(outputs, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7310438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Describe the video using sampled frames\n",
    "description = query_video(\n",
    "    prompt='Describe the video in detail.',\n",
    "    use_frames=True,\n",
    "    frames_path=frames_dir\n",
    ")\n",
    "print(description)\n",
    "\n",
    "# Example 2: Calculate velocity using full video\n",
    "velocity = query_video(\n",
    "    prompt='Calculate the velocity of the red dot.',\n",
    "    use_frames=False,\n",
    "    video_path=video_path\n",
    ")\n",
    "print(velocity)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
